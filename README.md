"# Latest_Pepper_code" 

The project "Gesture detection with an humanoid robot, Pepper" has the goal to create an andoid application and deply on Pepper's tablet. The design of the application includes a set of predefined gestures and a set of predefined actions to be performed after the gesture is detected. The Pepper robot's actions are based on the API's provided by Aldebaran. It mainly uses APIs like Human Awareness, Listen, Say, Goto, Chat and Animate. The main reference is taken from the Aldebaran's sample APIs.
